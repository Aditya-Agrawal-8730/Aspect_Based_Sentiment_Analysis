{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for [ABSApp](https://github.com/IntelLabs/nlp-architect/tree/master/solutions/absa_solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ABSApp_Preparation import file_no_preprocessing, file_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File Shape - (47883, 10)\n",
      "Null text rows removed - 4\n",
      "Processed File Shape - (47879, 1)\n"
     ]
    }
   ],
   "source": [
    "file_no_preprocessing(\n",
    "    read_path=\"csv_files\\TikTok_quitvaping_combined_cmts_20230227 (1).csv\",\n",
    "    text_column_name=\"text\",\n",
    "    save_path=\"output_files\\TikTok_quitvaping_combined_cmts_20230227_ABSApp.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File Shape - (47883, 10)\n",
      "Null text rows removed - 4\n",
      "Processed File Shape - (47879, 1)\n"
     ]
    }
   ],
   "source": [
    "file_preprocessing(\n",
    "    read_path=\"csv_files\\TikTok_quitvaping_combined_cmts_20230227 (1).csv\",\n",
    "    text_column_name=\"text\",\n",
    "    save_path=\"output_files\\TikTok_quitvaping_combined_cmts_20230227_ABSApp_pre_proc.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspects List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_categories_names = {1:\"Vape/vaping\", 2:\"Quitting\", 3:\"The video/account\", 4:\"Health\", 5:\"Chemicals\",\\\n",
    "                           6:\"Addiction\", 7:\"Finance\", 8:\"Other tobacco/substance\"}\n",
    "\n",
    "aspect_categories = {1:[\"vapes\",\"vape\",\"vaping\",\"hits\",\"hit\",\"carts\",\"cart\",\"puffs\",\"puff\",\"juice\",\"pods\",\"pod\",\"vape juice\",\"bars\",\"bar\",\"flavor\",\"liquid\"],\\\n",
    "                     2:[\"quit\",\"journey\",\"choice\",\"quitting\",\"decisions\",\"decision\"],\\\n",
    "                     3:[\"videos\",\"video\",\"dude\",\"bro\",\"man\",\"girl\",\"brother\"],\\\n",
    "                     4:[\"lungs\",\"lung\",\"health\",\"skin\",\"cough\",\"body\",\"teeth\",\"tooth\",\"throat\"],\\\n",
    "                     5:[\"chemicals\"],\\\n",
    "                     6:[\"addiction\",\"cravings\",\"craving\",\"nicotine\",\"urge\"],\\\n",
    "                     7:[\"money\"],\\\n",
    "                     8:[\"cigs\",\"cig\",\"smoking\",\"drugs\",\"drug\",\"cigarettes\",\"cigarette\",\"drinking\",\"tobacco\",\"pouches\",\"pouch\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "Version 1.16.27 of pyabsa is outdated. Version 2.4.1 was released Friday February 23, 2024.\n",
      "\u001b[31mPyABSA INFO: The PyABSA >= 2.0.0 version contains breaking changes, if you want to use the training and inference scripts (in demos directory), please do not upgrade to the >= 2.0.0 version\u001b[0m\n",
      "\u001b[31mcheck release notes at https://github.com/yangheng95/PyABSA/blob/release/release-note.json\u001b[0m\n",
      "********** \u001b[32mAvailable apc model checkpoints for Version:1.16.27 (this version)\u001b[0m **********\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: english\n",
      "id: \n",
      "Training Model: FAST-LSA-T-V2\n",
      "Training Dataset: English\n",
      "Language: English\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.6.3+\n",
      "Checkpoint File: fast_lsa_t_v2_English_acc_84.01_f1_83.77.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: chinese\n",
      "id: https://drive.google.com/file/d/1B0RHazOCm2eOWLWExQkeapHr9d3OiZl7/view?usp=sharing\n",
      "Training Model: FAST-LCF-MDeBERTa\n",
      "Training Dataset: Chinese\n",
      "Language: Chinese\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.8.2+\n",
      "Checkpoint File: fast_lcf_bert_Chinese_acc_97.11_f1_96.54.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: multilingual\n",
      "id: \n",
      "Training Model: FAST-LSA-T-V2\n",
      "Training Dataset: Multilingual\n",
      "Language: Multilingual\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.8.2+\n",
      "Checkpoint File: fast_lsa_t_v2_Multilingual_acc_83.18_f1_82.84.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: HELP-WANTED\n",
      "id: \n",
      "Description: You can help us by sharing checkpoints (e.g. models trained on you own datasets) with community.\n",
      "Checkpoint File: PLEASE NOTE THAT THIS IS NOT A REAL CHECKPOINT!\n",
      "Available Version: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[33mThere may be some checkpoints available for early versions of PyABSA, see apc\u001b[0m\n",
      "Load sentiment classifier from checkpoints\\APC_MULTILINGUAL_CHECKPOINT\n",
      "config: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.config\n",
      "state_dict: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.state_dict\n",
      "model: None\n",
      "tokenizer: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\functional\\checkpoint\\checkpoint_manager.py:259: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if max_ver == 'N.A.' or StrictVersion(min_ver) <= StrictVersion(__version__) <= StrictVersion(max_ver):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Fail to load the model from \nDebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n! Please make sure the version of checkpoint and PyABSA are compatible. Try to remove he checkpoint and download again \nException: checkpoints\\APC_MULTILINGUAL_CHECKPOINT ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\core\\apc\\prediction\\sentiment_classifier.py:81\u001b[0m, in \u001b[0;36mSentimentClassifier.__init__\u001b[1;34m(self, model_arg, cal_perplexity, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict_path:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAPCEnsembler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(state_dict_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\core\\apc\\models\\ensembler.py:87\u001b[0m, in \u001b[0;36mAPCEnsembler.__init__\u001b[1;34m(self, opt, load_dataset, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_lower_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_bert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mpretrained_bert) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:880\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    878\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m         )\n\u001b[1;32m--> 880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2110\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2108\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2335\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2336\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\deberta_v2\\tokenization_deberta_v2_fast.py:103\u001b[0m, in \u001b[0;36mDebertaV2TokenizerFast.__init__\u001b[1;34m(self, vocab_file, tokenizer_file, do_lower_case, split_by_punct, bos_token, eos_token, unk_token, sep_token, pad_token, cls_token, mask_token, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     vocab_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_lower_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_lower_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_by_punct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_by_punct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:117\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m slow_tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# We need to convert a slow tokenizer to build the backend\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslow_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# We need to convert a slow tokenizer to build the backend\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1631\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[1;34m(transformer_tokenizer)\u001b[0m\n\u001b[0;32m   1629\u001b[0m converter_class \u001b[38;5;241m=\u001b[39m SLOW_TO_FAST_CONVERTERS[tokenizer_class_name]\n\u001b[1;32m-> 1631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverter_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconverted()\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:546\u001b[0m, in \u001b[0;36mSpmConverter.__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 546\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotobuf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\utils\\import_utils.py:1463\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nDebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyABSA\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\PyABSA.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyabsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APCCheckpointManager, ABSADatasetList\n\u001b[0;32m     18\u001b[0m checkpoint_map \u001b[38;5;241m=\u001b[39m available_checkpoints(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapc\u001b[39m\u001b[38;5;124m'\u001b[39m, show_ckpts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#remove\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m sent_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mAPCCheckpointManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sentiment_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultilingual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use CUDA if available\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalizeToken\u001b[39m(token):\n\u001b[0;32m     22\u001b[0m     lowercased_token \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\utils\\pyabsa_utils.py:272\u001b[0m, in \u001b[0;36mretry.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    274\u001b[0m         TransformerConnectionError,\n\u001b[0;32m    275\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBaseHTTPError,\n\u001b[0;32m    282\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Exception: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, will retry later\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)))\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\functional\\checkpoint\\checkpoint_manager.py:71\u001b[0m, in \u001b[0;36mAPCCheckpointManager.get_sentiment_classifier\u001b[1;34m(checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m APCCheckpointManager\u001b[38;5;241m.\u001b[39mget_checkpoint(checkpoint)\n\u001b[1;32m---> 71\u001b[0m sent_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sent_classifier\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\core\\apc\\prediction\\sentiment_classifier.py:117\u001b[0m, in \u001b[0;36mSentimentClassifier.__init__\u001b[1;34m(self, model_arg, cal_perplexity, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m             print_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFail to load the model from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    118\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease make sure the version of checkpoint and PyABSA are compatible.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    119\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Try to remove he checkpoint and download again\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e, model_arg))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(APCModelList, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Fail to load the model from \nDebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n! Please make sure the version of checkpoint and PyABSA are compatible. Try to remove he checkpoint and download again \nException: checkpoints\\APC_MULTILINGUAL_CHECKPOINT "
     ]
    }
   ],
   "source": [
    "import PyABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** \u001b[32mAvailable apc model checkpoints for Version:1.16.27 (this version)\u001b[0m **********\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: english\n",
      "id: \n",
      "Training Model: FAST-LSA-T-V2\n",
      "Training Dataset: English\n",
      "Language: English\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.6.3+\n",
      "Checkpoint File: fast_lsa_t_v2_English_acc_84.01_f1_83.77.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: chinese\n",
      "id: https://drive.google.com/file/d/1B0RHazOCm2eOWLWExQkeapHr9d3OiZl7/view?usp=sharing\n",
      "Training Model: FAST-LCF-MDeBERTa\n",
      "Training Dataset: Chinese\n",
      "Language: Chinese\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.8.2+\n",
      "Checkpoint File: fast_lcf_bert_Chinese_acc_97.11_f1_96.54.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: multilingual\n",
      "id: \n",
      "Training Model: FAST-LSA-T-V2\n",
      "Training Dataset: Multilingual\n",
      "Language: Multilingual\n",
      "Description: Trained on RTX3090\n",
      "Available Version: 1.8.2+\n",
      "Checkpoint File: fast_lsa_t_v2_Multilingual_acc_83.18_f1_82.84.zip\n",
      "Author: H, Yang (yangheng@m.scnu.edu.cn)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Checkpoint Name: HELP-WANTED\n",
      "id: \n",
      "Description: You can help us by sharing checkpoints (e.g. models trained on you own datasets) with community.\n",
      "Checkpoint File: PLEASE NOTE THAT THIS IS NOT A REAL CHECKPOINT!\n",
      "Available Version: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[33mThere may be some checkpoints available for early versions of PyABSA, see apc\u001b[0m\n",
      "Load sentiment classifier from checkpoints\\APC_MULTILINGUAL_CHECKPOINT\n",
      "config: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.config\n",
      "state_dict: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.state_dict\n",
      "model: None\n",
      "tokenizer: checkpoints\\APC_MULTILINGUAL_CHECKPOINT\\fast_lsa_t_v2.tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--yangheng--deberta-v3-base-absa-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Fail to load the model from Error(s) in loading state_dict for APCEnsembler:\n\tUnexpected key(s) in state_dict: \"models.0.bert4global.embeddings.position_ids\", \"bert.embeddings.position_ids\". ! Please make sure the version of checkpoint and PyABSA are compatible. Try to remove he checkpoint and download again \nException: checkpoints\\APC_MULTILINGUAL_CHECKPOINT ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\core\\apc\\prediction\\sentiment_classifier.py:82\u001b[0m, in \u001b[0;36mSentimentClassifier.__init__\u001b[1;34m(self, model_arg, cal_perplexity, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m APCEnsembler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt, load_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_path:\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for APCEnsembler:\n\tUnexpected key(s) in state_dict: \"models.0.bert4global.embeddings.position_ids\", \"bert.embeddings.position_ids\". ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyABSA\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\PyABSA.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyabsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APCCheckpointManager, ABSADatasetList\n\u001b[0;32m     18\u001b[0m checkpoint_map \u001b[38;5;241m=\u001b[39m available_checkpoints(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapc\u001b[39m\u001b[38;5;124m'\u001b[39m, show_ckpts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#remove\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m sent_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mAPCCheckpointManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sentiment_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultilingual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use CUDA if available\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalizeToken\u001b[39m(token):\n\u001b[0;32m     22\u001b[0m     lowercased_token \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\utils\\pyabsa_utils.py:272\u001b[0m, in \u001b[0;36mretry.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    274\u001b[0m         TransformerConnectionError,\n\u001b[0;32m    275\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBaseHTTPError,\n\u001b[0;32m    282\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Exception: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, will retry later\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)))\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\functional\\checkpoint\\checkpoint_manager.py:71\u001b[0m, in \u001b[0;36mAPCCheckpointManager.get_sentiment_classifier\u001b[1;34m(checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m APCCheckpointManager\u001b[38;5;241m.\u001b[39mget_checkpoint(checkpoint)\n\u001b[1;32m---> 71\u001b[0m sent_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sent_classifier\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\pyabsa\\core\\apc\\prediction\\sentiment_classifier.py:117\u001b[0m, in \u001b[0;36mSentimentClassifier.__init__\u001b[1;34m(self, model_arg, cal_perplexity, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m             print_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFail to load the model from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    118\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease make sure the version of checkpoint and PyABSA are compatible.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    119\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Try to remove he checkpoint and download again\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e, model_arg))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(APCModelList, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Fail to load the model from Error(s) in loading state_dict for APCEnsembler:\n\tUnexpected key(s) in state_dict: \"models.0.bert4global.embeddings.position_ids\", \"bert.embeddings.position_ids\". ! Please make sure the version of checkpoint and PyABSA are compatible. Try to remove he checkpoint and download again \nException: checkpoints\\APC_MULTILINGUAL_CHECKPOINT "
     ]
    }
   ],
   "source": [
    "import PyABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyABSA.print_pyabsa_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = \"Original_Dataset/TikTok_quitvaping_combined_cmts_20230227.csv\"\n",
    "text_column_name = \"text\"\n",
    "save_path_1 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_ASC_category_list_04_16.csv\"\n",
    "save_path_2 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_ASC_category_average_04_16.csv\"\n",
    "save_path_3 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_ASC_category_aspect_count_04_16.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyABSA.main(\n",
    "    read_path = \"csv_files\\TikTok_quitvaping_combined_cmts_20230227 (1).csv\",\n",
    "    text_column_name = \"text\", \n",
    "    aspect_categories= aspect_categories,\n",
    "    save_path_1 = \"output_files\\TikTok_quitvaping_combined_cmts_ASC_category_list_06_05.csv\", \n",
    "    save_path_2 = \"output_files\\TikTok_quitvaping_combined_cmts_ASC_category_average_06_05.csv\", \n",
    "    save_path_3 = \"output_files\\TikTok_quitvaping_combined_cmts_ASC_category_aspect_count_06_05.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available- False\n",
      "Device Used - cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\cache_huggingface_transformers\\models--yangheng--deberta-v3-base-absa-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\cache_huggingface_transformers\\models--cardiffnlp--twitter-xlm-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: We had a great experience at the restaurant, food was delicious, but the service was kinda bad\n",
      "\n",
      "Sentiment of aspect 'food' is:\n",
      "Label negative: 0.0009989123791456223\n",
      "Label neutral: 0.0018238142365589738\n",
      "Label positive: 0.997177243232727\n",
      "\n",
      "Sentiment of aspect 'service' is:\n",
      "Label negative: 0.9946129322052002\n",
      "Label neutral: 0.002369985682889819\n",
      "Label positive: 0.003017079783603549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DeBERTa.print_deberta_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_1 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_DeBERTa_category_list_04_16.csv\"\n",
    "save_path_2 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_DeBERTa_category_average_04_16.csv\"\n",
    "save_path_3 = \"Sentiment_Classified_Outputs/TikTok_quitvaping_combined_cmts_DeBERTa_category_aspect_count_04_16.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence \\T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File Shape - (47883, 10)\n",
      "Processing Text......\n",
      "Processed File Shape - (47879, 11)\n",
      "0 .  It's a hard life \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Progress = 0/47879\n",
      "1 .  :beaming_face_with_smiling_eyes: :beaming_face_with_smiling_eyes: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2 .  Si we y amaneces turuleka \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3 .  how much coast one \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4 .  ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5 .  This is content I need \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6 .  Shiiiit \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7 .  W :loudly_crying_face: :loudly_crying_face: :loudly_crying_face: :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8 .  Sana oll \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9 .  :face_with_tears_of_joy: :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 .  Yes 🙌🏻 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11 .  \" I don't have to smoke anymore ! \" That is such a powerful way of looking at it . \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12 .  What's your top 3 ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13 .  i so proud :smiling_face_with_tear: :face_with_tears_of_joy: :pleading_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "14 .  YESSIRR \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "15 .  @USER \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "16 .  MY BABIES \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "17 .  powerful \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18 .  my turn \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "19 .  Here's your crown :crown: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "20 .  no \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "21 .  Wayne this is so inspirational :thumbs_up: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "22 .  This is tuff :cold_face: :folded_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "23 .  keep spreading the message \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "24 .  :loudly_crying_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 .  FYPPP \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "26 .  So friggen happy for you , freedom looks great on you 🙌🏻 :red_heart: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "27 .  Imagine waking up with energy just because you don't smoke or vape 👌🏻 \n",
      "\n",
      "vape 2 {'negative': 0.1039, 'neutral': 0.8736, 'positive': 0.0225}\n",
      "1\n",
      "vape\n",
      "\n",
      "\n",
      "\n",
      "28 .  I'm on day 7 and I don't feel “ better ” I cried in the vape store parking lot and it took me 30 minutes to convince myself to head home ... 1 year vaping . \n",
      "\n",
      "vape 2 {'negative': 0.0086, 'neutral': 0.9732, 'positive': 0.0183}\n",
      "1\n",
      "vape\n",
      "vaping 2 {'negative': 0.0057, 'neutral': 0.9746, 'positive': 0.0197}\n",
      "1\n",
      "vape, vaping\n",
      "\n",
      "\n",
      "\n",
      "29 .  When my bf was quitting and got a craving he put the money he would spend into a savings account and quickly realised how much money he was saving \n",
      "\n",
      "quitting 3 {'negative': 0.0584, 'neutral': 0.3764, 'positive': 0.5652}\n",
      "2\n",
      "quitting\n",
      "craving 2 {'negative': 0.0327, 'neutral': 0.9115, 'positive': 0.0558}\n",
      "6\n",
      "craving\n",
      "money 3 {'negative': 0.0149, 'neutral': 0.0313, 'positive': 0.9538}\n",
      "7\n",
      "money\n",
      "\n",
      "\n",
      "\n",
      "30 .  proud \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "31 .  I'm never quitting \n",
      "\n",
      "quitting 3 {'negative': 0.0481, 'neutral': 0.0236, 'positive': 0.9283}\n",
      "2\n",
      "quitting\n",
      "\n",
      "\n",
      "\n",
      "32 .  Lmao you don't have to hide it if you never try to quit . Take the L \n",
      "\n",
      "quit 1 {'negative': 0.977, 'neutral': 0.0119, 'positive': 0.0111}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "33 .  Ik u tryna quit but those Zyns aren't helping you at all \n",
      "\n",
      "quit 1 {'negative': 0.919, 'neutral': 0.0692, 'positive': 0.0117}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "34 .  W bro \n",
      "\n",
      "bro 2 {'negative': 0.2482, 'neutral': 0.4782, 'positive': 0.2736}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "35 .  can i get 1 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "36 .  @USER 🧑‍🚀 :beaver: nu er han ik sej mer \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "37 .  Day 55 ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "38 .  I'm trying to quit so that's for sharing this is inspiring to me ! \n",
      "\n",
      "quit 3 {'negative': 0.0254, 'neutral': 0.2496, 'positive': 0.7251}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "39 .  I quit smoking a year and a half ago but I did it with nicotine pouches . I am slowly going down on mg . I can still breathe better than w cigs \n",
      "\n",
      "quit 2 {'negative': 0.1053, 'neutral': 0.6498, 'positive': 0.2449}\n",
      "2\n",
      "quit\n",
      "nicotine 2 {'negative': 0.0044, 'neutral': 0.9771, 'positive': 0.0185}\n",
      "6\n",
      "nicotine\n",
      "cigs 2 {'negative': 0.1945, 'neutral': 0.777, 'positive': 0.0286}\n",
      "8\n",
      "cigs\n",
      "smoking 1 {'negative': 0.5571, 'neutral': 0.3763, 'positive': 0.0666}\n",
      "8\n",
      "cigs, smoking\n",
      "pouches 2 {'negative': 0.0165, 'neutral': 0.7033, 'positive': 0.2802}\n",
      "8\n",
      "cigs, smoking, pouches\n",
      "\n",
      "\n",
      "\n",
      "40 .  Good work bro ! \n",
      "\n",
      "bro 3 {'negative': 0.0014, 'neutral': 0.0053, 'positive': 0.9933}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "41 .  5 months clean here . feel amazing bro . keep it up \n",
      "\n",
      "bro 3 {'negative': 0.0006, 'neutral': 0.004, 'positive': 0.9954}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "42 .  Can't believe a week flew by that quickly , I'm glad you made it this far , keep it going ! :hundred_points: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "43 .  I'm still broke but yes ! I feel a million times better and wonder why I ever started :smiling_face_with_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "44 .  I love your videos , Valerie ! :red_heart: \n",
      "\n",
      "videos 3 {'negative': 0.0004, 'neutral': 0.0011, 'positive': 0.9985}\n",
      "3\n",
      "videos\n",
      "\n",
      "\n",
      "\n",
      "45 .  @USER \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "46 .  What are your resources \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "47 .  I'm good but thank you \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "48 .  on my fyp the first day of wearing a nic patch to quit :smiling_face_with_hearts: \n",
      "\n",
      "quit 1 {'negative': 0.9543, 'neutral': 0.0309, 'positive': 0.0148}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "49 .  What if you don't cough up gunk \n",
      "\n",
      "cough 1 {'negative': 0.9862, 'neutral': 0.0118, 'positive': 0.0021}\n",
      "4\n",
      "cough\n",
      "\n",
      "\n",
      "\n",
      "50 .  Hey my ex did that :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "51 .  Where you see that \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "52 .  too much Mackenzie everywhere \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "53 .  thank you \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "54 .  unlike you \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "55 .  it's fine I'm hanging in there \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "56 .  boylan \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "57 .  It's just constant withdrawal . Nicotine is an addiction that IS hard to quit . Don't even get me started on the metal in your lungs ... \n",
      "\n",
      "quit 1 {'negative': 0.9922, 'neutral': 0.0054, 'positive': 0.0024}\n",
      "2\n",
      "quit\n",
      "lungs 1 {'negative': 0.9932, 'neutral': 0.0054, 'positive': 0.0013}\n",
      "4\n",
      "lungs\n",
      "addiction 1 {'negative': 0.9842, 'neutral': 0.0121, 'positive': 0.0037}\n",
      "6\n",
      "addiction\n",
      "nicotine 1 {'negative': 0.9812, 'neutral': 0.0137, 'positive': 0.0052}\n",
      "6\n",
      "addiction, nicotine\n",
      "\n",
      "\n",
      "\n",
      "58 .  Me and my gf are quitting next week and I've quit before for 6 months and I'm dreading the withdrawals again :grinning_face_with_sweat: I really hope this quit sticks \n",
      "\n",
      "quit 3 {'negative': 0.0625, 'neutral': 0.0919, 'positive': 0.8456}\n",
      "2\n",
      "quit\n",
      "quitting 3 {'negative': 0.1189, 'neutral': 0.1683, 'positive': 0.7128}\n",
      "2\n",
      "quit, quitting\n",
      "\n",
      "\n",
      "\n",
      "59 .  W content \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "60 .  THEN WHAT DOES IT TASTE LIKE ? ? ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "61 .  i just cant aford it sry \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "62 .  LMAO :face_with_tears_of_joy: :face_with_tears_of_joy: :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "63 .  No extra flavor BUT extra beautiful ! ! ! \n",
      "\n",
      "flavor 1 {'negative': 0.9366, 'neutral': 0.0432, 'positive': 0.0203}\n",
      "1\n",
      "flavor\n",
      "\n",
      "\n",
      "\n",
      "64 .  How old is u ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "65 .  Yessss :two_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "66 .  thank you so very much \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "67 .  still not vaping ? \n",
      "\n",
      "vaping 1 {'negative': 0.8934, 'neutral': 0.0948, 'positive': 0.0118}\n",
      "1\n",
      "vaping\n",
      "\n",
      "\n",
      "\n",
      "68 .  About to be 2 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "69 .  Congratulations \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "70 .  It's crazy tbh \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "71 .  Looking back they definitely knew what they were doing . \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "72 .  droom auto :smiling_face_with_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "73 .  :red_heart: ️‍🔥 :red_heart: ️‍🔥 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "74 .  Bugatti Veyron gezien ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "75 .  You guys she only telling him for his own good we all know she not the mom leave her alone \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "76 .  It's his choice lol \n",
      "\n",
      "choice 3 {'negative': 0.0148, 'neutral': 0.0983, 'positive': 0.887}\n",
      "2\n",
      "choice\n",
      "\n",
      "\n",
      "\n",
      "77 .  faut pas laisser ils vont te dérange pas \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "78 .  Puff puff pass g it's my turn \n",
      "\n",
      "puff 2 {'negative': 0.0621, 'neutral': 0.7625, 'positive': 0.1754}\n",
      "1\n",
      "puff\n",
      "\n",
      "\n",
      "\n",
      "79 .  2021 should just ban nic all around :smiling_face_with_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "80 .  android \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "81 .  Your the kid that quit vaping and won't stop telling everybody your struggle \n",
      "\n",
      "vaping 2 {'negative': 0.3319, 'neutral': 0.6508, 'positive': 0.0174}\n",
      "1\n",
      "vaping\n",
      "quit 2 {'negative': 0.0769, 'neutral': 0.8895, 'positive': 0.0337}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "82 .  can stopping make you look anymore youthful again ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "83 .  You spillin bruh .. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "84 .  this gave me the most insane early 2000s vibes \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "85 .  I'm 2 weeks without it now ! Great choice to make \n",
      "\n",
      "choice 3 {'negative': 0.0084, 'neutral': 0.0134, 'positive': 0.9782}\n",
      "2\n",
      "choice\n",
      "\n",
      "\n",
      "\n",
      "86 .  good job dude.you got this bro ! \n",
      "\n",
      "bro 3 {'negative': 0.0015, 'neutral': 0.0066, 'positive': 0.992}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "87 .  Wooooo get it ! Your doing great ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "88 .  just keep saying 1 more day \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "89 .  yoooo please keep grinding ! you got it brother :black_heart: \n",
      "\n",
      "brother 3 {'negative': 0.0121, 'neutral': 0.0462, 'positive': 0.9417}\n",
      "3\n",
      "brother\n",
      "\n",
      "\n",
      "\n",
      "90 .  Thanks for sharing brother . Glory be to God ! God bless ya \n",
      "\n",
      "brother 3 {'negative': 0.0064, 'neutral': 0.0731, 'positive': 0.9206}\n",
      "3\n",
      "brother\n",
      "\n",
      "\n",
      "\n",
      "91 .  It's crazy because the moment I found out I was pregnant with just daughter the lord also removed my desire entirely . Glory Be To God 🙌🏾 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "92 .  bro read Quran \n",
      "\n",
      "bro 2 {'negative': 0.0204, 'neutral': 0.7147, 'positive': 0.265}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "93 .  Thanks Nick I'm having the same problem quitting vaping too , bless you :butterfly: :smiling_face_with_halo: :baby_angel: :folded_hands: :folded_hands: :shamrock: \n",
      "\n",
      "vaping 2 {'negative': 0.0905, 'neutral': 0.9022, 'positive': 0.0073}\n",
      "1\n",
      "vaping\n",
      "quitting 1 {'negative': 0.8031, 'neutral': 0.1818, 'positive': 0.0152}\n",
      "2\n",
      "quitting\n",
      "\n",
      "\n",
      "\n",
      "94 .  I need to quit smoking and just can't get myself to do it \n",
      "\n",
      "quit 1 {'negative': 0.6507, 'neutral': 0.1334, 'positive': 0.2159}\n",
      "2\n",
      "quit\n",
      "smoking 1 {'negative': 0.8877, 'neutral': 0.0984, 'positive': 0.0139}\n",
      "8\n",
      "smoking\n",
      "\n",
      "\n",
      "\n",
      "95 .  could you tell me more about quitting smoking , please . \n",
      "\n",
      "quitting 2 {'negative': 0.0203, 'neutral': 0.965, 'positive': 0.0147}\n",
      "2\n",
      "quitting\n",
      "smoking 2 {'negative': 0.206, 'neutral': 0.7841, 'positive': 0.0098}\n",
      "8\n",
      "smoking\n",
      "\n",
      "\n",
      "\n",
      "96 .  Liberty ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "97 .  This is a good idea . I feel like you have to have self discipline as well to say no to friends once the offer \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "98 .  And suckers or jolly ranchers things like that , get rid of anything and everything linked with vapes best way to go is cold turkey and tough it out \n",
      "\n",
      "vapes 2 {'negative': 0.0568, 'neutral': 0.9306, 'positive': 0.0125}\n",
      "1\n",
      "vapes\n",
      "\n",
      "\n",
      "\n",
      "99 .  @USER thank you a lot ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 .  how do you feel so far ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Progress = 100/47879\n",
      "101 .  let's go ! keep it up ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "102 .  @USER . maks I feel amazing . To be honest it is way easier than I thought :relieved_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "103 .  Working progress ! Praise the Lord :raising_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "104 .  Now you know ... :flushed_face: :pleading_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "105 .  The content I signed up for \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "106 .  okay hairline reveal :folded_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "107 .  First \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "108 .  @USER ele é bonito e engraçado \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "109 .  lemme cheif \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "110 .  i need help ugh \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "111 .  Nah \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "112 .  I need help stopping before surgery \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "113 .  HOHOHO ! that's :face_with_tears_of_joy: :face_with_tears_of_joy: :face_with_tears_of_joy: funny because they know they don't need it but they need it :grinning_face_with_sweat: :grinning_face_with_sweat: :grinning_face_with_sweat: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "114 .  On gosh ! :face_with_tears_of_joy: That stuffs bad for you ! STOP THAT ! ! :beaming_face_with_smiling_eyes: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "115 .  @USER .. b0yfri3nd \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "116 .  Fear ! ! Interesting \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "117 .  Ahhhh Fear of Failure . Yes indeed plays a part . \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "118 .  im scared because when something really stresses me out , even after 4 months of not smoking ... i run to buy cigerettes :flushed_face: :pleading_face: \n",
      "\n",
      "smoking 2 {'negative': 0.4785, 'neutral': 0.4993, 'positive': 0.0222}\n",
      "8\n",
      "smoking\n",
      "\n",
      "\n",
      "\n",
      "119 .  I have tried to quit so many times :( \n",
      "\n",
      "quit 1 {'negative': 0.9863, 'neutral': 0.009, 'positive': 0.0048}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "120 .  anticipatory failure . Such a road block on the path to success :beaming_face_with_smiling_eyes: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "121 .  Good for you girl ! :smiling_face_with_hearts: \n",
      "\n",
      "girl 3 {'negative': 0.0011, 'neutral': 0.0031, 'positive': 0.9958}\n",
      "3\n",
      "girl\n",
      "\n",
      "\n",
      "\n",
      "122 .  in her influencer era :star-struck: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "123 .  we all know he took it out after the video \n",
      "\n",
      "video 2 {'negative': 0.2649, 'neutral': 0.7302, 'positive': 0.005}\n",
      "3\n",
      "video\n",
      "\n",
      "\n",
      "\n",
      "124 .  I love Vinny I love Vinny \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "125 .  How did this get so many views - :loudly_crying_face: 🤛🏻 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "126 .  King \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "127 .  Lose a little weight . Not as much stress . Cut back on coffee etc \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "128 .  Good job ! :smiling_face_with_hearts: You got this \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "129 .  Goodluck ! You got rhis :smiling_face_with_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "130 .  same here sis im still at 5 % :grimacing_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "131 .  gimme da vape \n",
      "\n",
      "vape 3 {'negative': 0.0075, 'neutral': 0.026, 'positive': 0.9665}\n",
      "1\n",
      "vape\n",
      "\n",
      "\n",
      "\n",
      "132 .  Its honestly so hard for me bc i feel like its my only coping mechanism i have to help relieve stress and anxiety . Ik it sounds bad . \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "133 .  I need help :melting_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "134 .  The vapes are terrible . My trigger was alcohol . The minute I had a drink I would crack . I was short of breath everyday . Good thing you stopped . \n",
      "\n",
      "vapes 1 {'negative': 0.9973, 'neutral': 0.0015, 'positive': 0.0012}\n",
      "1\n",
      "vapes\n",
      "\n",
      "\n",
      "\n",
      "135 .  Thank you for sharing . I want to quit \n",
      "\n",
      "quit 3 {'negative': 0.012, 'neutral': 0.0427, 'positive': 0.9453}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "136 .  Share \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "137 .  I need them asap \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "138 .  I want those so bad \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "139 .  DAYNM \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "140 .  I'll rather be vaping . \n",
      "\n",
      "vaping 3 {'negative': 0.0076, 'neutral': 0.0306, 'positive': 0.9618}\n",
      "1\n",
      "vaping\n",
      "\n",
      "\n",
      "\n",
      "141 .  Sour candies helped me ! ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "142 .  You got this ! It took me 6 years of on and off and then 3 months of reeeealpy trying before it stuck \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "143 .  you smiling fr or showing your teeth as a warning ? Love you ! \n",
      "\n",
      "teeth 2 {'negative': 0.0453, 'neutral': 0.5013, 'positive': 0.4534}\n",
      "4\n",
      "teeth\n",
      "\n",
      "\n",
      "\n",
      "144 .  Good luck ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "145 .  She's not quitting \n",
      "\n",
      "quitting 1 {'negative': 0.8209, 'neutral': 0.0843, 'positive': 0.0949}\n",
      "2\n",
      "quitting\n",
      "\n",
      "\n",
      "\n",
      "146 .  Okay I'll admit . I dropped mine in my cats litter . And then I cleaned it off with a make up brush and hit it \n",
      "\n",
      "hit 2 {'negative': 0.163, 'neutral': 0.8242, 'positive': 0.0128}\n",
      "1\n",
      "hit\n",
      "\n",
      "\n",
      "\n",
      "147 .  I dug mine out of the bathroom trashcan at CRSSD @USER Maiman :face_with_tears_of_joy: :flushed_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "148 .  Quiting once I destroy athens tomorrow night \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "149 .  Nic gum is a lifesaver if you're trying to quit Ik 5 people that switched to gum and 3 of them just chew normal gum now \n",
      "\n",
      "quit 3 {'negative': 0.0273, 'neutral': 0.1543, 'positive': 0.8185}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "150 .  Facebook.com/groups/1812975135566803 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "151 .  Well I've shocked myself ... day 2 of no vape just my patch ! :face_with_open_mouth: :grinning_squinting_face: so happy ! Thanks for posts ! X \n",
      "\n",
      "vape 2 {'negative': 0.4211, 'neutral': 0.5152, 'positive': 0.0638}\n",
      "1\n",
      "vape\n",
      "\n",
      "\n",
      "\n",
      "152 .  National no smoking day Wednesday 9th March 2022 - let's do this \n",
      "\n",
      "smoking 1 {'negative': 0.7428, 'neutral': 0.1514, 'positive': 0.1058}\n",
      "8\n",
      "smoking\n",
      "\n",
      "\n",
      "\n",
      "153 .  Ill need to know exactly where you threw that \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "154 .  :face_with_tears_of_joy: :clapping_hands: :clapping_hands: :clapping_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "155 .  he's cute asf \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "156 .  Wait why was u on the ground lol \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "157 .  :pleading_face: :pleading_face: Why does TikTok keep taking this video down \n",
      "\n",
      "video 1 {'negative': 0.6431, 'neutral': 0.3168, 'positive': 0.0401}\n",
      "3\n",
      "video\n",
      "\n",
      "\n",
      "\n",
      "158 .  Puff bars :face_with_tears_of_joy: \n",
      "\n",
      "puff 2 {'negative': 0.0068, 'neutral': 0.8041, 'positive': 0.1892}\n",
      "1\n",
      "puff\n",
      "bars 2 {'negative': 0.0054, 'neutral': 0.854, 'positive': 0.1406}\n",
      "1\n",
      "puff, bars\n",
      "\n",
      "\n",
      "\n",
      "159 .  That's me \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "160 .  Omg love this song \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "161 .  need to quit \n",
      "\n",
      "quit 1 {'negative': 0.4477, 'neutral': 0.4066, 'positive': 0.1457}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "162 .  Wanting to quit \n",
      "\n",
      "quit 2 {'negative': 0.1982, 'neutral': 0.4513, 'positive': 0.3505}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "163 .  Found out this week that I'm pregnant and trying so hard to quit but WOW it's kicking my ass \n",
      "\n",
      "quit 1 {'negative': 0.9748, 'neutral': 0.0123, 'positive': 0.0129}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "164 .  FREE ISRAEL 🇮🇱 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "165 .  that was the plan \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "166 .  Fr \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "167 .  ong :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "168 .  this really said FOR YOU page :loudly_crying_face: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "169 .  It's been 3weeks for me and sooo hard I'm doing my best and I'm so proud I got this far :red_heart: 🧚🏾 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "170 .  After a few months , you won't even have the craving when you see them ! I choke when I try to hit one now . You got this :growing_heart: \n",
      "\n",
      "hit 1 {'negative': 0.9619, 'neutral': 0.0277, 'positive': 0.0104}\n",
      "1\n",
      "hit\n",
      "craving 1 {'negative': 0.9524, 'neutral': 0.0327, 'positive': 0.0149}\n",
      "6\n",
      "craving\n",
      "\n",
      "\n",
      "\n",
      "171 .  M \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "172 .  Giving me a damn taste bud lol :face_with_tears_of_joy: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "173 .  :white_heart: :white_heart: :white_heart: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "174 .  Was it Fr a usb I can't see ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "175 .  LOL \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "176 .  is this actually you ? You look exactly like I imagined you would \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "177 .  It wasn't that funny yo \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "178 .  Ooh why put them in water ? I thought they had little button batteries ? Don't they dissolve ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "179 .  very proud :clapping_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "180 .  omfg your necklaces look so good :smiling_face_with_hearts: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "181 .  Vergroot t gevoel wat je had als non-smoker ( zoals iedereen geboren is ) en visualiseer jezelf in die energie . Doe dit voor t slapen gaan aantal x \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "182 .  Positive vibes \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "183 .  how long have you been vaping & what anxieties do you have ab it \n",
      "\n",
      "vaping 2 {'negative': 0.0041, 'neutral': 0.982, 'positive': 0.0139}\n",
      "1\n",
      "vaping\n",
      "\n",
      "\n",
      "\n",
      "184 .  Would be interesting to see what ur VO2 max now ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "185 .  thanks for answering my question ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "186 .  I never realized a difference in breathing when running . I quit for 10 days . After starting again I realized difficulty breathing while running . \n",
      "\n",
      "quit 1 {'negative': 0.9776, 'neutral': 0.0192, 'positive': 0.0031}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "187 .  girl you got this well done :smiling_face_with_hearts: :smiling_face_with_hearts: \n",
      "\n",
      "girl 3 {'negative': 0.0015, 'neutral': 0.0034, 'positive': 0.9951}\n",
      "3\n",
      "girl\n",
      "\n",
      "\n",
      "\n",
      "188 .  Thank you for the video . I started cos my anxiety is always on level 10 but it makes me tired instead and yes it's EXPENSIVE EH ! \n",
      "\n",
      "video 3 {'negative': 0.0047, 'neutral': 0.0073, 'positive': 0.9879}\n",
      "3\n",
      "video\n",
      "\n",
      "\n",
      "\n",
      "189 .  Well done 👏🏽 👏🏽 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "190 .  1v1 ? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "191 .  Great message ! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "192 .  yo \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "193 .  Needing help .. came across this .. would love advice , I have a complicated history \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "194 .  :smiling_face_with_hearts: :smiling_face_with_hearts: best decision of my life \n",
      "\n",
      "decision 3 {'negative': 0.0019, 'neutral': 0.008, 'positive': 0.9901}\n",
      "2\n",
      "decision\n",
      "\n",
      "\n",
      "\n",
      "195 .  It's not hard to quit I just like the flavor I don't like breathing flavorless air \n",
      "\n",
      "flavor 3 {'negative': 0.0057, 'neutral': 0.0055, 'positive': 0.9888}\n",
      "1\n",
      "flavor\n",
      "quit 3 {'negative': 0.0403, 'neutral': 0.373, 'positive': 0.5866}\n",
      "2\n",
      "quit\n",
      "\n",
      "\n",
      "\n",
      "196 .  :beaming_face_with_smiling_eyes: :raising_hands: :raising_hands: :raising_hands: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "197 .  I'm smoking two packs a day please help me god please help me \n",
      "\n",
      "smoking 1 {'negative': 0.7093, 'neutral': 0.2745, 'positive': 0.0163}\n",
      "8\n",
      "smoking\n",
      "\n",
      "\n",
      "\n",
      "198 .  I'll take dark chocolate please :beaming_face_with_smiling_eyes: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "199 .  Me sitting here with the same vape :face_with_tears_of_joy: :face_with_tears_of_joy: :face_with_tears_of_joy: \n",
      "\n",
      "vape 2 {'negative': 0.0046, 'neutral': 0.9439, 'positive': 0.0515}\n",
      "1\n",
      "vape\n",
      "\n",
      "\n",
      "\n",
      "200 .  What kind of vape is that bro ? \n",
      "\n",
      "vape 2 {'negative': 0.0472, 'neutral': 0.9472, 'positive': 0.0056}\n",
      "1\n",
      "vape\n",
      "bro 1 {'negative': 0.6596, 'neutral': 0.332, 'positive': 0.0084}\n",
      "3\n",
      "bro\n",
      "\n",
      "\n",
      "\n",
      "Progress = 200/47879\n",
      "201 .  Ong \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "202 .  Oldy but a goody \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "Progress = 300/47879\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "Progress = 400/47879\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "Progress = 500/47879\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "Progress = 600/47879\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "Progress = 700/47879\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "Progress = 800/47879\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "Progress = 900/47879\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "Progress = 1000/47879\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_20648\\241674665.py:2: DeprecationWarning: invalid escape sequence \\T\n",
      "  read_path = \"csv_files\\TikTok_quitvaping_combined_cmts_20230227 (1).csv\",\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDeBERTa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv_files\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTikTok_quitvaping_combined_cmts_20230227 (1).csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_column_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43maspect_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maspect_categories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_files\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTikTok_quitvaping_combined_cmts_DeBERTa_category_list_06_05.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_files\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTikTok_quitvaping_combined_cmts_DeBERTa_category_average_06_05.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_files\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTikTok_quitvaping_combined_cmts_DeBERTa_category_aspect_count_06_05.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\DeBERTa.py:317\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(read_path, text_column_name, aspect_categories, save_path_1, save_path_2, save_path_3)\u001b[0m\n\u001b[0;32m    314\u001b[0m df_og[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Sentiment Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m df_og[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Sentiment (1-Negative, 2-Neutral, 3-Positive)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 317\u001b[0m df_og_processed \u001b[38;5;241m=\u001b[39m \u001b[43mdeberta_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_og\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspects_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect_categories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiments & Confidence Scores Generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m save_df_csv(df_og_processed, save_path_1)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\DeBERTa.py:213\u001b[0m, in \u001b[0;36mdeberta_main\u001b[1;34m(df_og, aspects_list, aspect_categories)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[38;5;28mprint\u001b[39m(index) \u001b[38;5;66;03m#remove\u001b[39;00m\n\u001b[0;32m    211\u001b[0m             \u001b[38;5;28mprint\u001b[39m(df_og\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAspect_Category_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(index)]) \u001b[38;5;66;03m#remove\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m rest, cat \u001b[38;5;241m=\u001b[39m \u001b[43mget_aspect_overall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m df_og\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Sentiment Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(rest)\n\u001b[0;32m    215\u001b[0m df_og\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Sentiment (1-Negative, 2-Neutral, 3-Positive)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cat)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - Boston University\\GitHub Repo\\BU_TikTok_ABSA_VS_Code_2\\DeBERTa.py:138\u001b[0m, in \u001b[0;36mget_aspect_overall\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    136\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m sentiment_tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    137\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m encoded_input\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    140\u001b[0m scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1205\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1205\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1217\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:834\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    825\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    827\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    828\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    829\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    833\u001b[0m )\n\u001b[1;32m--> 834\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    847\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:522\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    511\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    512\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    513\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         output_attentions,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:411\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    401\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:347\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    330\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    338\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    339\u001b[0m         hidden_states,\n\u001b[0;32m    340\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m         output_attentions,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[1;32m--> 347\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Visual Studio Code - i3simulations\\Virtual_Environments\\venv_BU_2406_03\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:291\u001b[0m, in \u001b[0;36mXLMRobertaSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    289\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    290\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m--> 291\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m)\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DeBERTa.main(\n",
    "    read_path = \"csv_files\\TikTok_quitvaping_combined_cmts_20230227 (1).csv\",\n",
    "    text_column_name = \"text\", \n",
    "    aspect_categories= aspect_categories,\n",
    "    save_path_1 = \"output_files\\TikTok_quitvaping_combined_cmts_DeBERTa_category_list_06_05.csv\", \n",
    "    save_path_2 = \"output_files\\TikTok_quitvaping_combined_cmts_DeBERTa_category_average_06_05.csv\", \n",
    "    save_path_3 = \"output_files\\TikTok_quitvaping_combined_cmts_DeBERTa_category_aspect_count_06_05.csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_BU_2406_05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
